{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a4Yo3s3XKxwC"
   },
   "source": [
    "# **EEC 174AY Lab 2: Supervised Learning**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eifd9F6TKxwD"
   },
   "source": [
    "## **Outline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4hLejyIiKxwD"
   },
   "source": [
    "1. Basics of Python Pandas for Reading & Manipulating Data\n",
    "    - Assignment #1\n",
    "2. Introduction to Scikit-Learn (package used for more traditional machine learning tools), create an RF model\n",
    "    - Assignment #2\n",
    "    - Assignment #3\n",
    "3. Improving your model: Feature Selection\n",
    "    - Assignmnet #4\n",
    "    - Assignment #5\n",
    "4. K-Fold Validation\n",
    "    - Assignment #6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K1m4dgABKxwE"
   },
   "source": [
    "# **1. Basics of Python Pandas for Reading & Manipulating Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UrnNOOogKxwE"
   },
   "source": [
    "### **1.1: Reading Data into Memory**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VHEnPpgCYg7B"
   },
   "source": [
    "For this lab, we will be looking at ventilator data of patients' breath patterns. We will be working with *train x* and *train y* datasets to train a model. Then, we will use *test x* and *test y* datasets to validate our model.\n",
    "\n",
    "First, let's load in our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "js2NIqh5KxwF"
   },
   "outputs": [],
   "source": [
    "# make sure we can plot in future if we want\n",
    "# %matplotlib notebook\n",
    "# make sure to ignore warnings\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "# Import statement for pandas\n",
    "import pandas as pd\n",
    "# This is just a small configuration change for purposes of the class\n",
    "pd.options.display.max_rows = 10\n",
    "\n",
    "# Get our train X and y datasets for the problem\n",
    "train_x = pd.read_csv('ece174_pva_train_x.csv')\n",
    "train_y = pd.read_csv('ece174_pva_train_y.csv')\n",
    "\n",
    "# Get our validation X and y datasets for the problem.\n",
    "test_x = pd.read_csv('ece174_pva_validation_x.csv')\n",
    "test_y = pd.read_csv('ece174_pva_validation_y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "GIHWJcVsKxwI",
    "outputId": "b6ecc74b-807d-4c82-eab0-89b30b2bdb5c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>breath_id</th>\n",
       "      <th>i_time</th>\n",
       "      <th>tve</th>\n",
       "      <th>max_flow</th>\n",
       "      <th>min_flow</th>\n",
       "      <th>max_pressure</th>\n",
       "      <th>peep</th>\n",
       "      <th>ip_auc</th>\n",
       "      <th>ep_auc</th>\n",
       "      <th>patient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>545.032222</td>\n",
       "      <td>51.06</td>\n",
       "      <td>-41.03</td>\n",
       "      <td>17.37</td>\n",
       "      <td>7.600</td>\n",
       "      <td>11.122367</td>\n",
       "      <td>16.057733</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.80</td>\n",
       "      <td>531.880278</td>\n",
       "      <td>53.13</td>\n",
       "      <td>-39.97</td>\n",
       "      <td>17.13</td>\n",
       "      <td>7.508</td>\n",
       "      <td>11.077750</td>\n",
       "      <td>17.310533</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.86</td>\n",
       "      <td>523.876667</td>\n",
       "      <td>52.86</td>\n",
       "      <td>-38.24</td>\n",
       "      <td>17.11</td>\n",
       "      <td>7.658</td>\n",
       "      <td>12.066000</td>\n",
       "      <td>16.697800</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.80</td>\n",
       "      <td>507.636111</td>\n",
       "      <td>51.04</td>\n",
       "      <td>-39.37</td>\n",
       "      <td>17.14</td>\n",
       "      <td>7.572</td>\n",
       "      <td>11.097800</td>\n",
       "      <td>15.774250</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.80</td>\n",
       "      <td>518.618889</td>\n",
       "      <td>47.88</td>\n",
       "      <td>-38.51</td>\n",
       "      <td>16.92</td>\n",
       "      <td>7.598</td>\n",
       "      <td>11.065400</td>\n",
       "      <td>18.483333</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5970</th>\n",
       "      <td>296</td>\n",
       "      <td>0.90</td>\n",
       "      <td>355.365278</td>\n",
       "      <td>42.26</td>\n",
       "      <td>-51.51</td>\n",
       "      <td>23.53</td>\n",
       "      <td>13.194</td>\n",
       "      <td>19.216400</td>\n",
       "      <td>21.816367</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5971</th>\n",
       "      <td>297</td>\n",
       "      <td>0.90</td>\n",
       "      <td>316.806944</td>\n",
       "      <td>42.10</td>\n",
       "      <td>-55.17</td>\n",
       "      <td>24.61</td>\n",
       "      <td>12.896</td>\n",
       "      <td>19.800467</td>\n",
       "      <td>21.739700</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5972</th>\n",
       "      <td>298</td>\n",
       "      <td>0.92</td>\n",
       "      <td>395.971111</td>\n",
       "      <td>42.95</td>\n",
       "      <td>-22.47</td>\n",
       "      <td>21.35</td>\n",
       "      <td>13.090</td>\n",
       "      <td>16.997767</td>\n",
       "      <td>21.457600</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5973</th>\n",
       "      <td>299</td>\n",
       "      <td>0.90</td>\n",
       "      <td>373.426389</td>\n",
       "      <td>40.34</td>\n",
       "      <td>-36.81</td>\n",
       "      <td>21.69</td>\n",
       "      <td>13.334</td>\n",
       "      <td>17.944000</td>\n",
       "      <td>21.798167</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5974</th>\n",
       "      <td>300</td>\n",
       "      <td>0.90</td>\n",
       "      <td>364.684444</td>\n",
       "      <td>42.29</td>\n",
       "      <td>-45.94</td>\n",
       "      <td>22.69</td>\n",
       "      <td>13.002</td>\n",
       "      <td>18.679800</td>\n",
       "      <td>21.801950</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5975 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      breath_id  i_time         tve  max_flow  min_flow  max_pressure    peep  \\\n",
       "0             1    0.80  545.032222     51.06    -41.03         17.37   7.600   \n",
       "1             2    0.80  531.880278     53.13    -39.97         17.13   7.508   \n",
       "2             3    0.86  523.876667     52.86    -38.24         17.11   7.658   \n",
       "3             4    0.80  507.636111     51.04    -39.37         17.14   7.572   \n",
       "4             5    0.80  518.618889     47.88    -38.51         16.92   7.598   \n",
       "...         ...     ...         ...       ...       ...           ...     ...   \n",
       "5970        296    0.90  355.365278     42.26    -51.51         23.53  13.194   \n",
       "5971        297    0.90  316.806944     42.10    -55.17         24.61  12.896   \n",
       "5972        298    0.92  395.971111     42.95    -22.47         21.35  13.090   \n",
       "5973        299    0.90  373.426389     40.34    -36.81         21.69  13.334   \n",
       "5974        300    0.90  364.684444     42.29    -45.94         22.69  13.002   \n",
       "\n",
       "         ip_auc     ep_auc  patient  \n",
       "0     11.122367  16.057733       66  \n",
       "1     11.077750  17.310533       66  \n",
       "2     12.066000  16.697800       66  \n",
       "3     11.097800  15.774250       66  \n",
       "4     11.065400  18.483333       66  \n",
       "...         ...        ...      ...  \n",
       "5970  19.216400  21.816367      662  \n",
       "5971  19.800467  21.739700      662  \n",
       "5972  16.997767  21.457600      662  \n",
       "5973  17.944000  21.798167      662  \n",
       "5974  18.679800  21.801950      662  \n",
       "\n",
       "[5975 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output some rows of the dataset just to get a better feel for the information\n",
    "train_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "39Ui7iD2KxwM"
   },
   "source": [
    "**Features**\n",
    "\n",
    "The data currently has 10 columns above. Later in Assignment 1 you will increase these to 18. Below is a description of all 18 columns or *features*. Note that some column information cannot be featurized such as `patient` or `breath_id`.\n",
    "\n",
    " * `breath_id`: matches with a specific breath identifier from the raw data file.\n",
    " * `patient`: the patient the data came from\n",
    " * `min_flow`: The minimum flow observation on the breath\n",
    " * `max_flow`: The maximum flow observation on the breath\n",
    " * `tvi`: The inhaled volume of air for each breath\n",
    " * `tve`: The exhaled volume of air for each breath\n",
    " * `tve_tvi_ratio`: The ratio of `tve / tvi`\n",
    " * `i_time`: The amount of time patient was breathing in for each breath\n",
    " * `e_time`: The amount of time patient was breathing out for each breath\n",
    " * `ie_ratio`: The ratio of `i_time / e_time`\n",
    " * `rr`: The respiratory rate in number of breaths per minute. Measured by `60 / (i_time + e_time)`\n",
    " * `min_pressure`: the minimum pressure observation on the breath\n",
    " * `max_pressure`: the maximum pressure observation on the breath\n",
    " * `peep`: - the baseline pressure setting on the ventilator\n",
    " * `pip`: the maximum pressure setting of inspiration. Slight difference compared to max_pressure\n",
    " * `maw`: the mean pressure for the entire breath\n",
    " * `ip_auc`: the area under the curve of the inspiratory pressure\n",
    " * `ep_auc`: the area under the curve of the expiratory pressure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sv401xQKqWzb"
   },
   "source": [
    "### **1.2: Featurization**\n",
    "\n",
    "Featurization is the process where you extract information from raw data. This information can then be fed into a machine learning algorithm to perform the task you want. In the current case we will need to extract additional information from the ventilator data in order to create a valid machine learning classifier.\n",
    "\n",
    "#### Processing the Data\n",
    "The first step we need to do is to be able to read the raw data files and put them into memory.\n",
    "\n",
    "Here, we load in the ventilator data stored in the patient CSV files and organize them by breath cycles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "3F9zM2XXqWze"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "def process_ventilator_data(filename):\n",
    "    descriptor = open(filename)\n",
    "    reader = csv.reader(descriptor)\n",
    "    breath_id = 1\n",
    "\n",
    "    all_breath_data = []\n",
    "    current_flow_data = []\n",
    "    current_pressure_data = []\n",
    "\n",
    "    for row in reader:\n",
    "        if (row[0].strip() == 'BS' or row[0].strip() == 'BE') and current_flow_data != []:\n",
    "            all_breath_data.append({'breath_id': breath_id, 'flow': current_flow_data, 'pressure': current_pressure_data})\n",
    "            breath_id += 1\n",
    "            current_flow_data = []\n",
    "            current_pressure_data = []\n",
    "        else:\n",
    "            try:\n",
    "                current_flow_data.append(round(float(row[0]), 2))\n",
    "                current_pressure_data.append(round(float(row[1]), 2))\n",
    "            except (IndexError, ValueError):\n",
    "                continue\n",
    "    return all_breath_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-9QZPmuTqWzg"
   },
   "source": [
    "Now that we have the capability to read ventilator data into memory, we should try to visualize what the data looks like.\n",
    "We will be extracting just one breath cycle to visualize the breath flow and pressure of the patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LBTNTT7mqWzh",
    "outputId": "63e5581f-06a8-4946-a0fa-72006519cffd"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_files = glob(os.path.join('data', '*/*.csv'))\n",
    "example_file = data_files[0]\n",
    "breath_data = process_ventilator_data(example_file)\n",
    "flow = breath_data[0]['flow']\n",
    "pressure = breath_data[0]['pressure']\n",
    "plt.plot(flow, label='flow')\n",
    "plt.plot(pressure, label='pressure')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PvqL1vh-qWzj"
   },
   "source": [
    "## **Assignment \\#1: Featurization**\n",
    "\n",
    "Now that we've visualized the data we need to featurize the data so we can use it in a ML algorithm. We'll need a bit more code to do this. We've already given you 10 features above that you can use for the current models. Your assignment will be to process the rest of the 8 features based on the requirements and hints that I've given in the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "eFcw0M7IqWzk"
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "\n",
    "# import for Simpson's method. This will be helpful for calculating TVi\n",
    "from scipy.integrate import simps\n",
    "from statistics import mean\n",
    "\n",
    "\n",
    "def extract_features_for_file(filename, existing_features):\n",
    "    \"\"\"\n",
    "    Extract features for every single breath in file. To make matters a bit easier, we use\n",
    "    existing features that we've already extracted from the file to help speed the process.\n",
    "    \"\"\"\n",
    "    patient = filename.split('/')[-2]\n",
    "    all_breath_data = process_ventilator_data(filename)\n",
    "    all_features = []\n",
    "\n",
    "    for breath_data in all_breath_data:\n",
    "        breath_id = breath_data['breath_id']\n",
    "        existing_breath_features = existing_features[existing_features.breath_id == breath_id].iloc[0]\n",
    "\n",
    "        flow = breath_data['flow']\n",
    "        pressure = breath_data['pressure']\n",
    "\n",
    "        # inspiratory time (the amount of time a patient is inhaling for)\n",
    "        i_time = existing_breath_features.i_time\n",
    "        # exhaled tidal volume\n",
    "        tve = existing_breath_features.tve\n",
    "        # maximum flow for breath\n",
    "        max_flow = existing_breath_features.max_flow\n",
    "        # minimum flow for the breath\n",
    "        min_flow = existing_breath_features.min_flow\n",
    "        # maximum pressure for the breath\n",
    "        max_pressure = existing_breath_features.max_pressure\n",
    "        # The minimum pressure setting on the ventilator\n",
    "        peep = existing_breath_features.peep\n",
    "        # The area under the curve of the inspiratory pressure curve\n",
    "        ip_auc = existing_breath_features.ip_auc\n",
    "        # The area under the curve of the expiratory pressure curve\n",
    "        ep_auc = existing_breath_features.ep_auc\n",
    "\n",
    "        # This is the array index where the inhalation ends. We divide by 0.02 because\n",
    "        # thats how frequently the ventilator samples data, every 0.02 seconds.\n",
    "        x0_index = int(i_time / 0.02)\n",
    "\n",
    "        # Part of your assignment is to extract the following features for all breaths:\n",
    "        #\n",
    "        # Expiratory Time. The amount of time a patient is exhaling\n",
    "        # time unit: second\n",
    "        e_time = len(flow) * 0.02 - i_time\n",
    "        \n",
    "        #\n",
    "        # I:E ratio. The ratio of inspiratory to expiratory time. Measured by i_time/e_time\n",
    "        i_e_ratio = i_time / e_time \n",
    "\n",
    "        #\n",
    "        # Respiratory rate. The number of breaths a patient is breathing. This is measured by\n",
    "        # 60 / (total breath time in seconds)\n",
    "        rr = 60 / (i_time + e_time)\n",
    "\n",
    "        #\n",
    "        # Tidal volume inhaled. The amount of air volume inhaled in the breath.\n",
    "        # Hint: use the simps function.\n",
    "        # This will output volume in L/min, convert to ml/sec (* 1000 / 60)\n",
    "        tvi = simps(flow[:x0_index]) * 1000 / 60\n",
    "\n",
    "        #\n",
    "        # Tidal volume ratio. Measured by tve/tvi\n",
    "        tve_tvi_ratio = tve / tvi\n",
    "\n",
    "        #\n",
    "        # Minimum pressure of the breath\n",
    "        min_pressure = min(pressure)\n",
    "\n",
    "        #\n",
    "        # PIP - peak inspiratory pressure. The peak pressure during inhalation\n",
    "        pip = max(pressure[:x0_index])\n",
    "\n",
    "        #\n",
    "        # MAW - mean airway pressure for inhalation.\n",
    "        maw = mean(pressure[:x0_index])\n",
    "\n",
    "\n",
    "        all_features.append([\n",
    "            breath_id, i_time, e_time, i_e_ratio, rr, tvi, tve, tve_tvi_ratio,\n",
    "            max_flow, min_flow, max_pressure, min_pressure, pip, maw,\n",
    "            peep, ip_auc, ep_auc, int(patient)\n",
    "        ])\n",
    "    columns = [\n",
    "        'breath_id', 'i_time', 'e_time', 'i_e_ratio', 'rr', 'tvi', 'tve',\n",
    "        'tve_tvi_ratio', 'max_flow', 'min_flow', 'max_pressure',\n",
    "        'min_pressure', 'pip', 'maw', 'peep', 'ip_auc', 'ep_auc', 'patient'\n",
    "    ]\n",
    "    return all_features, columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "2MbfyxdpqWzl"
   },
   "outputs": [],
   "source": [
    "def remake_dataset(dataset):\n",
    "    data_files = glob(os.path.join('data', '*/*.csv'))\n",
    "\n",
    "    patient_to_file_map = {}\n",
    "    for filename in data_files:\n",
    "        patient = filename.split('/')[-2]  # patient is embedded in this part of filename\n",
    "        patient_to_file_map[patient] = filename\n",
    "\n",
    "    data = []\n",
    "    # iterate over all the unique patients in the train set\n",
    "    for patient in dataset.patient.unique():\n",
    "        existing_features = dataset[dataset.patient == patient]\n",
    "        filename = patient_to_file_map[str(patient)]\n",
    "        breath_data, columns = extract_features_for_file(filename, existing_features)\n",
    "        # add breath rows\n",
    "        data.extend(breath_data)\n",
    "    # create new data frame with the new added information\n",
    "    return pd.DataFrame(data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "WJ1vnHBEqWzl"
   },
   "outputs": [],
   "source": [
    "# remake train set\n",
    "train_x = remake_dataset(train_x)\n",
    "# remake validation set.\n",
    "test_x = remake_dataset(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "sryx5NOoqWzm"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>breath_id</th>\n",
       "      <th>i_time</th>\n",
       "      <th>e_time</th>\n",
       "      <th>i_e_ratio</th>\n",
       "      <th>rr</th>\n",
       "      <th>tvi</th>\n",
       "      <th>tve</th>\n",
       "      <th>tve_tvi_ratio</th>\n",
       "      <th>max_flow</th>\n",
       "      <th>min_flow</th>\n",
       "      <th>max_pressure</th>\n",
       "      <th>min_pressure</th>\n",
       "      <th>pip</th>\n",
       "      <th>maw</th>\n",
       "      <th>peep</th>\n",
       "      <th>ip_auc</th>\n",
       "      <th>ep_auc</th>\n",
       "      <th>patient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.66</td>\n",
       "      <td>0.481928</td>\n",
       "      <td>24.390244</td>\n",
       "      <td>24096.152778</td>\n",
       "      <td>545.032222</td>\n",
       "      <td>0.022619</td>\n",
       "      <td>51.06</td>\n",
       "      <td>-41.03</td>\n",
       "      <td>17.37</td>\n",
       "      <td>7.04</td>\n",
       "      <td>17.37</td>\n",
       "      <td>14.208500</td>\n",
       "      <td>7.600</td>\n",
       "      <td>11.122367</td>\n",
       "      <td>16.057733</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>23.076923</td>\n",
       "      <td>24235.625000</td>\n",
       "      <td>531.880278</td>\n",
       "      <td>0.021946</td>\n",
       "      <td>53.13</td>\n",
       "      <td>-39.97</td>\n",
       "      <td>17.13</td>\n",
       "      <td>7.04</td>\n",
       "      <td>17.13</td>\n",
       "      <td>14.149500</td>\n",
       "      <td>7.508</td>\n",
       "      <td>11.077750</td>\n",
       "      <td>17.310533</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.74</td>\n",
       "      <td>0.494253</td>\n",
       "      <td>23.076923</td>\n",
       "      <td>26068.500000</td>\n",
       "      <td>523.876667</td>\n",
       "      <td>0.020096</td>\n",
       "      <td>52.86</td>\n",
       "      <td>-38.24</td>\n",
       "      <td>17.11</td>\n",
       "      <td>7.04</td>\n",
       "      <td>17.11</td>\n",
       "      <td>14.311860</td>\n",
       "      <td>7.658</td>\n",
       "      <td>12.066000</td>\n",
       "      <td>16.697800</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>24.590164</td>\n",
       "      <td>24196.069444</td>\n",
       "      <td>507.636111</td>\n",
       "      <td>0.020980</td>\n",
       "      <td>51.04</td>\n",
       "      <td>-39.37</td>\n",
       "      <td>17.14</td>\n",
       "      <td>7.04</td>\n",
       "      <td>17.14</td>\n",
       "      <td>14.174500</td>\n",
       "      <td>7.572</td>\n",
       "      <td>11.097800</td>\n",
       "      <td>15.774250</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.94</td>\n",
       "      <td>0.412371</td>\n",
       "      <td>21.897810</td>\n",
       "      <td>23314.680556</td>\n",
       "      <td>518.618889</td>\n",
       "      <td>0.022244</td>\n",
       "      <td>47.88</td>\n",
       "      <td>-38.51</td>\n",
       "      <td>16.92</td>\n",
       "      <td>7.04</td>\n",
       "      <td>16.92</td>\n",
       "      <td>14.131250</td>\n",
       "      <td>7.598</td>\n",
       "      <td>11.065400</td>\n",
       "      <td>18.483333</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5970</th>\n",
       "      <td>296</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>17484.111111</td>\n",
       "      <td>355.365278</td>\n",
       "      <td>0.020325</td>\n",
       "      <td>42.26</td>\n",
       "      <td>-51.51</td>\n",
       "      <td>23.53</td>\n",
       "      <td>13.00</td>\n",
       "      <td>23.53</td>\n",
       "      <td>21.750667</td>\n",
       "      <td>13.194</td>\n",
       "      <td>19.216400</td>\n",
       "      <td>21.816367</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5971</th>\n",
       "      <td>297</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>17506.500000</td>\n",
       "      <td>316.806944</td>\n",
       "      <td>0.018097</td>\n",
       "      <td>42.10</td>\n",
       "      <td>-55.17</td>\n",
       "      <td>24.61</td>\n",
       "      <td>12.80</td>\n",
       "      <td>24.61</td>\n",
       "      <td>22.414667</td>\n",
       "      <td>12.896</td>\n",
       "      <td>19.800467</td>\n",
       "      <td>21.739700</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5972</th>\n",
       "      <td>298</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.58</td>\n",
       "      <td>0.582278</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>17722.166667</td>\n",
       "      <td>395.971111</td>\n",
       "      <td>0.022343</td>\n",
       "      <td>42.95</td>\n",
       "      <td>-22.47</td>\n",
       "      <td>21.35</td>\n",
       "      <td>12.90</td>\n",
       "      <td>21.35</td>\n",
       "      <td>18.785435</td>\n",
       "      <td>13.090</td>\n",
       "      <td>16.997767</td>\n",
       "      <td>21.457600</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5973</th>\n",
       "      <td>299</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>16897.055556</td>\n",
       "      <td>373.426389</td>\n",
       "      <td>0.022100</td>\n",
       "      <td>40.34</td>\n",
       "      <td>-36.81</td>\n",
       "      <td>21.69</td>\n",
       "      <td>13.02</td>\n",
       "      <td>21.69</td>\n",
       "      <td>20.308444</td>\n",
       "      <td>13.334</td>\n",
       "      <td>17.944000</td>\n",
       "      <td>21.798167</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5974</th>\n",
       "      <td>300</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>17127.833333</td>\n",
       "      <td>364.684444</td>\n",
       "      <td>0.021292</td>\n",
       "      <td>42.29</td>\n",
       "      <td>-45.94</td>\n",
       "      <td>22.69</td>\n",
       "      <td>12.90</td>\n",
       "      <td>22.69</td>\n",
       "      <td>21.145778</td>\n",
       "      <td>13.002</td>\n",
       "      <td>18.679800</td>\n",
       "      <td>21.801950</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5975 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      breath_id  i_time  e_time  i_e_ratio         rr           tvi  \\\n",
       "0             1    0.80    1.66   0.481928  24.390244  24096.152778   \n",
       "1             2    0.80    1.80   0.444444  23.076923  24235.625000   \n",
       "2             3    0.86    1.74   0.494253  23.076923  26068.500000   \n",
       "3             4    0.80    1.64   0.487805  24.590164  24196.069444   \n",
       "4             5    0.80    1.94   0.412371  21.897810  23314.680556   \n",
       "...         ...     ...     ...        ...        ...           ...   \n",
       "5970        296    0.90    1.60   0.562500  24.000000  17484.111111   \n",
       "5971        297    0.90    1.60   0.562500  24.000000  17506.500000   \n",
       "5972        298    0.92    1.58   0.582278  24.000000  17722.166667   \n",
       "5973        299    0.90    1.60   0.562500  24.000000  16897.055556   \n",
       "5974        300    0.90    1.60   0.562500  24.000000  17127.833333   \n",
       "\n",
       "             tve  tve_tvi_ratio  max_flow  min_flow  max_pressure  \\\n",
       "0     545.032222       0.022619     51.06    -41.03         17.37   \n",
       "1     531.880278       0.021946     53.13    -39.97         17.13   \n",
       "2     523.876667       0.020096     52.86    -38.24         17.11   \n",
       "3     507.636111       0.020980     51.04    -39.37         17.14   \n",
       "4     518.618889       0.022244     47.88    -38.51         16.92   \n",
       "...          ...            ...       ...       ...           ...   \n",
       "5970  355.365278       0.020325     42.26    -51.51         23.53   \n",
       "5971  316.806944       0.018097     42.10    -55.17         24.61   \n",
       "5972  395.971111       0.022343     42.95    -22.47         21.35   \n",
       "5973  373.426389       0.022100     40.34    -36.81         21.69   \n",
       "5974  364.684444       0.021292     42.29    -45.94         22.69   \n",
       "\n",
       "      min_pressure    pip        maw    peep     ip_auc     ep_auc  patient  \n",
       "0             7.04  17.37  14.208500   7.600  11.122367  16.057733       66  \n",
       "1             7.04  17.13  14.149500   7.508  11.077750  17.310533       66  \n",
       "2             7.04  17.11  14.311860   7.658  12.066000  16.697800       66  \n",
       "3             7.04  17.14  14.174500   7.572  11.097800  15.774250       66  \n",
       "4             7.04  16.92  14.131250   7.598  11.065400  18.483333       66  \n",
       "...            ...    ...        ...     ...        ...        ...      ...  \n",
       "5970         13.00  23.53  21.750667  13.194  19.216400  21.816367      662  \n",
       "5971         12.80  24.61  22.414667  12.896  19.800467  21.739700      662  \n",
       "5972         12.90  21.35  18.785435  13.090  16.997767  21.457600      662  \n",
       "5973         13.02  21.69  20.308444  13.334  17.944000  21.798167      662  \n",
       "5974         12.90  22.69  21.145778  13.002  18.679800  21.801950      662  \n",
       "\n",
       "[5975 rows x 18 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LIvewro3Kxw8"
   },
   "source": [
    "# **2. Introduction to Scikit-Learn**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RpTnvxTQKxw9"
   },
   "source": [
    "### **2.1: Create Ground Truth**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5T1G00_Uh5xd"
   },
   "source": [
    "We will use the corresponding *test y* dataset containing healthy non-PVA, Breath Stacking Asynchrony (bsa), and Double Trigger Asynchrony (dta) labels as the ground truth for training our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "554IC7sjKxw9",
    "outputId": "207f3b2a-0b30-4abd-afdb-80db15162ccc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>breath_id</th>\n",
       "      <th>patient</th>\n",
       "      <th>bsa</th>\n",
       "      <th>dta</th>\n",
       "      <th>cough</th>\n",
       "      <th>suction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>292</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>292</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>292</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>292</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>292</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>295</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243</th>\n",
       "      <td>296</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244</th>\n",
       "      <td>297</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>298</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>299</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1247 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      breath_id  patient  bsa  dta  cough  suction\n",
       "0            20      292    1    0      0        0\n",
       "1            21      292    1    0      0        0\n",
       "2            22      292    0    0      0        0\n",
       "3            23      292    1    0      0        0\n",
       "4            24      292    1    0      0        0\n",
       "...         ...      ...  ...  ...    ...      ...\n",
       "1242        295      114    0    0      0        0\n",
       "1243        296      114    0    0      0        0\n",
       "1244        297      114    0    0      0        0\n",
       "1245        298      114    0    0      0        0\n",
       "1246        299      114    0    0      0        0\n",
       "\n",
       "[1247 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the test dataset and set it up.\n",
    "test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0m0mCowYKxxA"
   },
   "source": [
    "What does this mean?\n",
    "\n",
    "We have 6 columns here\n",
    " * `breath_id`: matches with a specific breath identifier from the raw data file.\n",
    " * `patient`: the patient the data came from\n",
    " * `bsa`: Breath Stacking Asynchrony. A single breath where the patient is trapping air in their chest\n",
    " * `dta`: Double Trigger Asynchrony. Two breaths in a row where the patient is trapping air\n",
    " * `cough`: What it sounds like, when a patient coughs\n",
    " * `suction`:  Nurses perform suction procedures to remove excess fluid from an endotracheal tube. This waveform is indicative of that.\n",
    "\n",
    " Each patient will either have healthy breath pattern, breath stacking asynchrony, or double trigger asynchrony, indicated by which label is 1 or 0.\n",
    "\n",
    "Now that we understand what our columns are, we need to put it into a format where the machine can understand it and create a learning model. Because this is a multiclass model, let's just have *non-PVA breaths* be class 0, *breath stacking* can be class 1, *double trigger* can be class 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "M1w3zmlLKxxA",
    "outputId": "2a764853-64e5-4216-96a5-f2367ada8953"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       0\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "1242    0\n",
       "1243    0\n",
       "1244    0\n",
       "1245    0\n",
       "1246    0\n",
       "Length: 1247, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a multi-class y vector that we can use for training purposes.\n",
    "train_y_vector = train_y.bsa * 1 + train_y.dta * 2\n",
    "test_y_vector = test_y.bsa * 1 + test_y.dta * 2\n",
    "test_y_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xNE2tVoFKxxE"
   },
   "source": [
    "Therefore, there will be only three categories in our dataset (non-PVA, bsa, dta)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPCwspEcKxxE"
   },
   "source": [
    "### **2.2: Create and train a Random Forest Classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7kd9ZHfFjvTI"
   },
   "source": [
    "Let's finalize the dataset and remove misannotated examples first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "xbIcnYeFKxxC",
    "outputId": "d69caad3-4641-43ee-ec66-fcfe7532e4a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5438    3\n",
       "5440    3\n",
       "5521    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See if there places where the data was mis-annotated, where both double trigger and breath stack was annotated.\n",
    "# It's just good to know if this is happening or not so that we can either drop the data, or change it later on.\n",
    "train_y_vector[train_y_vector > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "KjvAoQ7jKxxF"
   },
   "outputs": [],
   "source": [
    "# Mark places where data is double annotated.\n",
    "misannotated_train = train_y_vector > 2\n",
    "misannotated_test = test_y_vector > 2\n",
    "\n",
    "# Drop data flagged above (~ is the NOT operator)\n",
    "train_x = train_x.loc[~misannotated_train]\n",
    "train_y_vector = train_y_vector.loc[~misannotated_train]\n",
    "\n",
    "# do same thing for test\n",
    "test_x = test_x.loc[~misannotated_test]\n",
    "test_y_vector = test_y_vector.loc[~misannotated_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "obUfkRN2j1n_"
   },
   "source": [
    "Let's also remove data that is NaN. This is very important because otherwise your model won't train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "uwtJ6X1FKxxH"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "The .any(axis=1) function basically says, if there are any NaNs in this *ROW* then mark the row as true.\n",
    "The .any(axis=0) would mark columns as True/False, but this isn't helpful now.\n",
    "'''\n",
    "\n",
    "nans_train = train_x.isna().any(axis=1)\n",
    "nans_test = test_x.isna().any(axis=1)\n",
    "\n",
    "# now filter them out of the dataset in the same way\n",
    "train_x = train_x.loc[~nans_train]\n",
    "train_y_vector = train_y_vector.loc[~nans_train]\n",
    "\n",
    "test_x = test_x.loc[~nans_test]\n",
    "test_y_vector = test_y_vector.loc[~nans_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LIuAcesskacC"
   },
   "source": [
    "Any time we drop things from a data frame or series in pandas it is often helpful to re-index the object.\n",
    "The index is usually a sequential ordering of the rows like 1, 2, ... n. Sometimes it can be different\n",
    "but for now we'll just use sequential ordering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "rIA_k6c0KxxK"
   },
   "outputs": [],
   "source": [
    "train_x.index = range(len(train_x))\n",
    "train_y_vector.index = range(len(train_y_vector))\n",
    "\n",
    "test_x.index = range(len(test_x))\n",
    "test_y_vector.index = range(len(test_y_vector))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0SeoRcApKxxM"
   },
   "source": [
    "Now we can train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "6DyY_ROoKxxM"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# initialize model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# don't use patient and breath_id columns\n",
    "columns_to_use = list(set(train_x.columns).difference(['patient', 'breath_id']))\n",
    "\n",
    "# fit the model to training\n",
    "model.fit(train_x[columns_to_use], train_y_vector)\n",
    "\n",
    "# Now that the model is fitted, evaluate how well it is performing\n",
    "predictions = model.predict(test_x[columns_to_use])\n",
    "\n",
    "\n",
    "'''\n",
    "The optimization below helps re-model the data in the train set slightly so that the first double\n",
    "trigger breath in training set is marked as a breath stack, and kept last double trigger breath a double trigger.\n",
    "You don't not need to understand this part of the code.\n",
    "'''\n",
    "\n",
    "\n",
    "for idx, pred in enumerate(predictions):\n",
    "    if pred == 2:\n",
    "        predictions[idx-1] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HsLc-skjjkP8"
   },
   "source": [
    "To evaluate our model, we can use `sklearn.metrics` from *scikit-learn*, since PyTorch doesn't have a built-in metrics module. The `classification_report()` function provides key stats like precision, recall, and F1 score, making it useful for quickly assessing performance, especially with multiple classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pH6-1Oc6KxxO",
    "outputId": "b7c94107-69a3-46fa-82a3-d9c615fd491a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93       842\n",
      "           1       0.86      0.96      0.91       301\n",
      "           2       1.00      0.04      0.07       104\n",
      "\n",
      "    accuracy                           0.89      1247\n",
      "   macro avg       0.92      0.66      0.64      1247\n",
      "weighted avg       0.90      0.89      0.85      1247\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(test_y_vector, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R-zgKgsdqWzx"
   },
   "source": [
    "### **2.3 Scaling for ML**\n",
    "Scaling data is often essential, especially for neural networks, and can improve performance in models like random forests. Common methods include:\n",
    "\n",
    "#### **2.3.1: Standardization**\n",
    "Standardization transforms data by subtracting the mean and dividing by the standard deviation:\n",
    "$$ \\frac{x_f - \\mu_f}{\\sigma_f} $$\n",
    "Where $x_f$ is the feature, $\\mu_f$ is the mean, and $\\sigma_f$ is the standard deviation. Scikit-Learn simplifies this:\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "train_set_scaled = scaler.fit_transform(train_set)\n",
    "test_set_scaled = scaler.transform(test_set)\n",
    "```\n",
    "\n",
    "#### **2.3.2 Min-Max Scaling**\n",
    "This method scales features to a [0, 1] range:\n",
    "\n",
    "$$ (x_f - min(x_f)) \\div (max(x_f) - min(x_f)) $$\n",
    "\n",
    "Where the `min` function is just finding the minimum value of a feature vector, and the `max` function is finding the maximum value of a feature vector. You can do this quickly in Scikit-Learn too.\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "train_set_scaled = scaler.fit_transform(train_set)\n",
    "test_set_scaled = scaler.transform(test_set)\n",
    "```\n",
    "\n",
    "#### **2.3.3 Robust Scaler**\n",
    "The robust scaler removes the median and scales by the interquartile range (IQR), making it effective for data with outliers. It's worth experimenting with different scalers to see what works best for your model.\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler = RobustScaler()\n",
    "train_set_scaled = scaler.fit_transform(train_set)\n",
    "test_set_scaled = scaler.transform(test_set)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_wGhG5iLKxxR"
   },
   "source": [
    "## **Assignment \\#2: Create a working model of a random forest classifier with all the features given.**\n",
    "\n",
    "If you've been able to featurize all your information correctly, let's move onto creating a random forest model for the completely featurized dataset. You **must** use one of the scaling strategies. Run your model 10 times to get performance scores for precision, recall, and f1-score. Average and report the results **per class**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "L_Q5h-iPKxxR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 precision: 0.9005479537609509\n",
      "Class 0 recall: 0.9614014251781473\n",
      "Class 0 f1-score: 0.9299789702466403\n",
      "Class 1 precision: 0.8456141364617858\n",
      "Class 1 recall: 0.9661129568106313\n",
      "Class 1 f1-score: 0.9018500733996854\n",
      "Class 2 precision: 0.9500000000000000\n",
      "Class 2 recall: 0.0365384615384615\n",
      "Class 2 f1-score: 0.0691059368352797\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "train_x_scaled = scaler.fit_transform(train_x)\n",
    "test_x_scaled = scaler.transform(test_x)\n",
    "\n",
    "# Function to train our model and is run 10 times\n",
    "def trainset(train_x_scaled, train_y_vector, test_x_scaled, test_y_vector, runs=10):\n",
    "\n",
    "#making our initialized values that will store our important scores \n",
    "    precision_scores = {0: [], 1: [], 2: []}\n",
    "    recall_scores = {0: [], 1: [], 2: []}\n",
    "    f1_scores = {0: [], 1: [], 2: []}\n",
    "\n",
    "    model = RandomForestClassifier()\n",
    "\n",
    "#loop to train the model and use the code earlier in the lab to fit and make prediction along with the optimization\n",
    "    for _ in range(runs):\n",
    "\n",
    "        # fit the model to training\n",
    "        model.fit(train_x_scaled, train_y_vector)\n",
    "\n",
    "        # Now that the model is fitted, evaluate how well it is performing\n",
    "        predictions = model.predict(test_x_scaled)\n",
    "\n",
    "        for idx, pred in enumerate(predictions):\n",
    "            if pred == 2:\n",
    "                predictions[idx-1] = 2\n",
    "\n",
    "        # testing using precision, recall, and f1-score\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(test_y_vector, predictions, labels=[0, 1, 2])\n",
    "\n",
    "        #This loop goes over each class (0, 1, 2), and appends the data\n",
    "        for i, label in enumerate([0, 1, 2]):  \n",
    "            precision_scores[label].append(precision[i])\n",
    "            recall_scores[label].append(recall[i])\n",
    "            f1_scores[label].append(f1[i])\n",
    "\n",
    "    return precision_scores, recall_scores, f1_scores\n",
    "\n",
    "# Running the model 10 times\n",
    "precision_scores, recall_scores, f1_scores = trainset(train_x_scaled, train_y_vector, test_x_scaled, test_y_vector, runs=10)\n",
    "\n",
    "\n",
    "#getting the averages \n",
    "avg_precision = {label: np.mean(scores) for label, scores in precision_scores.items()}\n",
    "avg_recall = {label: np.mean(scores) for label, scores in recall_scores.items()}\n",
    "avg_f1 = {label: np.mean(scores) for label, scores in f1_scores.items()}\n",
    "\n",
    "#printing our data, i chose to do it just like the slide and added the .16f to output all decimal points\n",
    "for label in [0, 1, 2]:\n",
    "    print(f\"Class {label} precision: {avg_precision[label]:.16f}\")\n",
    "    print(f\"Class {label} recall: {avg_recall[label]:.16f}\")\n",
    "    print(f\"Class {label} f1-score: {avg_f1[label]:.16f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jemGhTQHmF0R"
   },
   "source": [
    "## **Assignment #3: Comparison of Supervised ML Algorithms**\n",
    "\n",
    "In machine learning, much focus is placed on choosing the right algorithm. However, trying a different algorithm doesnâ€™t always improve performance and can sometimes complicate things. That said, it's important to explore different models that fit your problem.\n",
    "\n",
    "In this assignment, you need to implement *at least one* Supervised Learning model and compare its performance with the Random Forest model. Report metrics such as misclassification rate, precision, recall, F1-score, etc.\n",
    "\n",
    "### **Supervised Learning Algorithms to Consider:**\n",
    "- Neural Networks (use PyTorch/TensorFlow if preferred)\n",
    "- Logistic Regression\n",
    "- Naive Bayes\n",
    "- SVM (typically for binary classification but can be explored for multi-class)\n",
    "- etc.\n",
    "\n",
    "Hints:\n",
    "### Logistic Regression\n",
    "\n",
    "Now weâ€™ll run L1-regularized logistic regression on our dataset.\n",
    "You may use:\n",
    "```python\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "```\n",
    "* Fit a L1-regularized logistic regression model by letting python chose the regularization\n",
    "parameter itself.\n",
    "\n",
    "Hint:\n",
    "```python\n",
    "model = LogisticRegression(penalty='l1') # L1-regularized\n",
    "```\n",
    "\n",
    "### kNN Classifier\n",
    "\n",
    "Use kNN classifier model on our dataset.\n",
    "\n",
    "```python\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "F7WUAqCUkdv5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN Classifier Results (k=5):\n",
      "  Accuracy: 0.6728\n",
      "  Class 0 precision: 0.8416\n",
      "  Class 0 recall: 0.7067\n",
      "  Class 0 f1-score: 0.7682\n",
      "  Class 1 precision: 0.5295\n",
      "  Class 1 recall: 0.7741\n",
      "  Class 1 f1-score: 0.6289\n",
      "  Class 2 precision: 0.1100\n",
      "  Class 2 recall: 0.1058\n",
      "  Class 2 f1-score: 0.1078\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialize the scaler using only the columns that were specified earlier in columns_to_use\n",
    "scaler = StandardScaler()\n",
    "train_x_scaled = scaler.fit_transform(train_x[columns_to_use])\n",
    "test_x_scaled = scaler.transform(test_x[columns_to_use])\n",
    "\n",
    "# im using the kNN Classifier\n",
    "def trainknn(train_x_scaled, train_y_vector, test_x_scaled, test_y_vector, k=5):\n",
    "\n",
    "    # Initialize kNN model\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    \n",
    "     # fit the model to training\n",
    "    model.fit(train_x_scaled, train_y_vector)\n",
    "\n",
    "    # evaluate it\n",
    "    predictions = model.predict(test_x_scaled)\n",
    "\n",
    "    # calculates precision, recall, F1-score for each\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(test_y_vector, predictions, labels=[0, 1, 2])\n",
    "    \n",
    "    # calculates the overall accuracy\n",
    "    accuracy = accuracy_score(test_y_vector, predictions)\n",
    "\n",
    "    return precision, recall, f1, accuracy\n",
    "\n",
    "#  function is called with the scaled training and test data, and k=5\n",
    "knn_precision, knn_recall, knn_f1, knn_accuracy = trainknn(train_x_scaled, train_y_vector, test_x_scaled, test_y_vector, k=5)\n",
    "\n",
    "# Report the results using the k=5\n",
    "print(f\"kNN Classifier Results (k=5):\")\n",
    "print(f\"  Accuracy: {knn_accuracy:.4f}\")\n",
    "\n",
    "for label in [0, 1, 2]:\n",
    "    print(f\"  Class {label} precision: {knn_precision[label]:.4f}\")\n",
    "    print(f\"  Class {label} recall: {knn_recall[label]:.4f}\")\n",
    "    print(f\"  Class {label} f1-score: {knn_f1[label]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RR45eaoHkjsI"
   },
   "source": [
    "# **3. Feature Selection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BIA9uB-RlMeS"
   },
   "source": [
    "We know there are only 3 classes in our labels as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "IB9aWEVflOrs"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>breath_id</th>\n",
       "      <th>patient</th>\n",
       "      <th>bsa</th>\n",
       "      <th>dta</th>\n",
       "      <th>cough</th>\n",
       "      <th>suction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>292</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>292</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>292</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>292</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>292</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>295</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243</th>\n",
       "      <td>296</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244</th>\n",
       "      <td>297</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>298</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>299</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1247 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      breath_id  patient  bsa  dta  cough  suction\n",
       "0            20      292    1    0      0        0\n",
       "1            21      292    1    0      0        0\n",
       "2            22      292    0    0      0        0\n",
       "3            23      292    1    0      0        0\n",
       "4            24      292    1    0      0        0\n",
       "...         ...      ...  ...  ...    ...      ...\n",
       "1242        295      114    0    0      0        0\n",
       "1243        296      114    0    0      0        0\n",
       "1244        297      114    0    0      0        0\n",
       "1245        298      114    0    0      0        0\n",
       "1246        299      114    0    0      0        0\n",
       "\n",
       "[1247 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h9FKQZ8elWth"
   },
   "source": [
    "One thing to note is that we are using 16 different features for input into our model. Some of these features can be of little value to classifying whether a breath is asynchronous or not. So, one of the easiest things we can do for ourselves is to reduce the number of features that we have in an intelligent way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zxsb2wMFlnIh"
   },
   "source": [
    "### **3.1: $\\chi^2$ Feature Selection** (chi squared)\n",
    "\n",
    "The chi-squared (Ï‡Â²) test is an intuitive method for feature selection in classification problems. It evaluates whether a feature is independent of the target variableâ€”if so, the feature may not be useful for the model. A high Ï‡Â² value with a low p-value (â‰¤ 0.05) suggests that the feature is dependent on the outcome.\n",
    "\n",
    "Learn more about the chi-squared test on [Wikipedia](https://en.wikipedia.org/wiki/Chi-squared_test) and its application in [feature selection](https://nlp.stanford.edu/IR-book/html/htmledition/feature-selectionchi2-feature-selection-1.html).\n",
    "\n",
    "\n",
    "[Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html) provides a function for performing the Ï‡Â² test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "9y6_bLFOlU9P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2.0845956610565352e-15, 'ep_auc'), (4.1963626094156816e-10, 'tve'), (8.032273135835149e-06, 'e_time'), (9.867120183960791e-06, 'i_e_ratio'), (0.0064789968190118105, 'rr'), (0.018753422526064954, 'i_time'), (0.056752121480488624, 'ip_auc'), (0.15346609771450018, 'max_pressure'), (0.4176834544812468, 'min_flow'), (0.45399781936316896, 'peep'), (0.5040246270526789, 'pip'), (0.6017652297121289, 'maw'), (0.6801265398971335, 'max_flow'), (0.8455385940418909, 'tvi'), (0.9029585211862035, 'min_pressure'), (0.9987987662938473, 'tve_tvi_ratio')]\n"
     ]
    }
   ],
   "source": [
    "# this is the PrettyPrint function. Just makes things look a bit nicer on output.\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# get all columns in our dataset except patient and breath_id\n",
    "columns_to_use = list(set(train_x.columns).difference(['patient', 'breath_id']))\n",
    "\n",
    "# must scale feature vectors so they are non-negative\n",
    "scaler = MinMaxScaler()\n",
    "train_set = scaler.fit_transform(train_x[columns_to_use])\n",
    "\n",
    "# the chi2 test will output two things, chi2 and p values. The p values are the most relevant item that we want\n",
    "# to use. A feature with a p-value between 0 and 0.05 means that a feature might be a good predictor of our outcome.\n",
    "chi2_vals, pvals = chi2(train_set, train_y_vector)\n",
    "\n",
    "# mash column names with p-values so we know which p-value belongs to which feature\n",
    "cols_to_pvals = zip(pvals, columns_to_use)\n",
    "# Sort the p-values in ascending order (smallest first).\n",
    "cols_sorted = sorted(cols_to_pvals)\n",
    "# pretty print the sorted values.\n",
    "print(cols_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V5nGpik1ls29"
   },
   "source": [
    "There are 2 features that had p-values below 0.05:\n",
    "\n",
    " * tve\n",
    " * ep_auc\n",
    "\n",
    "So let's use these features for our next model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "9RVc17MylSc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.76       842\n",
      "           1       0.38      0.48      0.43       301\n",
      "           2       0.12      0.02      0.03       104\n",
      "\n",
      "    accuracy                           0.64      1247\n",
      "   macro avg       0.42      0.42      0.41      1247\n",
      "weighted avg       0.61      0.64      0.62      1247\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "columns_to_use = ['tve', 'ep_auc']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "train_set = scaler.fit_transform(train_x[columns_to_use])\n",
    "test_set = scaler.transform(test_x[columns_to_use])\n",
    "\n",
    "model.fit(train_set, train_y_vector)\n",
    "predictions = model.predict(test_set)\n",
    "for idx, pred in enumerate(predictions):\n",
    "    if pred == 2:\n",
    "        predictions[idx-1] = 2\n",
    "\n",
    "print(classification_report(test_y_vector, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nr0gCti2zz7J"
   },
   "source": [
    "Our performance dropped when using the Ï‡Â² test. Does this mean the method isn't suitable for our problem?\n",
    "\n",
    "**What's happening?**\n",
    "\n",
    "Although the Ï‡Â² test indicates certain features are relevant, they may not generalize well to the test set. This is common in machine learningâ€”features important in training don't always perform well in testing. Are there other feature selection methods that may generalize better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B2MZJ6msz6aZ"
   },
   "source": [
    "### **3.2: Expert Feature Selection**\n",
    "\n",
    "Expert knowledge, such as medical insights, can improve model performance. What medical knowledge can we use here?\n",
    "\n",
    "#### **3.2.1: Breath Stack (BSA)**\n",
    "When a patient traps air in their chest, it can be measured by the `tve_tvi_ratio`. Doctors annotated breaths with a `tve_tvi_ratio < .9`, excluding suction/cough or anomalies.\n",
    "\n",
    "<img src=\"bsa-breath.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "#### **3.2.2: Double Trigger (DTA)**\n",
    "Double trigger has a double-hump waveform pattern.\n",
    "\n",
    "<img src=\"dta-breaths.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "Doctors annotated it as:\n",
    "\n",
    "1. Not an anomaly\n",
    "2. First breath with `e_time < .3` seconds\n",
    "3. First breath with `tve_tvi_ratio < .25` or `0.25 <= tve_tvi_ratio < 0.5` and `tve < 100`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "COwEkp5mpJXj"
   },
   "source": [
    "## **Assignment \\#4a: Expert Feature Selection**\n",
    "\n",
    "Using the expert features above, write a function to give predictions on the train set.\n",
    "Then, create a classification report on your predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "U2_emlZZq7t7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94       842\n",
      "           1       0.82      0.98      0.89       301\n",
      "           2       0.50      0.02      0.04       104\n",
      "\n",
      "    accuracy                           0.89      1247\n",
      "   macro avg       0.75      0.65      0.62      1247\n",
      "weighted avg       0.86      0.89      0.85      1247\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# features from First breath with e_time < .3 seconds first breath with tve_tvi_ratio < .25 or 0.25 <= tve_tvi_ratio < 0.5 and tve < 100\n",
    "columns_to_use = ['tve_tvi_ratio', 'tve', 'e_time']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "train_set = scaler.fit_transform(train_x[columns_to_use])\n",
    "test_set = scaler.transform(test_x[columns_to_use])\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# fit the model on the training set\n",
    "model.fit(train_set, train_y_vector)\n",
    "\n",
    "# make predictions\n",
    "predictions = model.predict(test_set)\n",
    "\n",
    "#optimization\n",
    "for idx, pred in enumerate(predictions):\n",
    "    if pred == 2:\n",
    "        predictions[idx-1] = 2\n",
    "\n",
    "print(\"Classification Report\\n\")\n",
    "print(classification_report(test_y_vector, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xw5mxfgb0SqI"
   },
   "source": [
    "### **3.3: Other Feature Selection Methods**\n",
    "\n",
    "You can explore various methods for feature selection. Hereâ€™s a brief overview:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y-jjcvvnNK1c"
   },
   "source": [
    "#### **3.3.1: Wrapper Methods**\n",
    "This brute-force approach trains models with all possible feature combinations and selects the best based on performance on the validation set.\n",
    "\n",
    "**Pros:**\n",
    " * Easy to understand and code\n",
    " * Works with any model\n",
    "\n",
    "**Cons:**\n",
    " * Prone to overfitting\n",
    " * Time-consumingâ€”requires training $n!$ models for $n$ features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pnm80c9MNL53"
   },
   "source": [
    "#### **3.3.2: PCA (Principal Component Analysis)**\n",
    "[PCA](https://en.wikipedia.org/wiki/Principal_component_analysis) transforms data into new, uncorrelated features. You choose the number of features, then train and evaluate models.\n",
    "\n",
    "**Pros:**\n",
    " * Speeds up model training through dimensionality reduction\n",
    " * Features are linearly uncorrelated\n",
    " * Easy to use with libraries like [Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)\n",
    "\n",
    "**Cons:**\n",
    " * Potential loss of information, which can reduce performance\n",
    " * Features lose interpretability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LPDIltrONRiK"
   },
   "source": [
    "#### **3.3.3: Mutual Information**\n",
    "[Mutual Information](https://en.wikipedia.org/wiki/Mutual_information) measures the dependency between a feature and the target. A higher value indicates greater dependency.\n",
    "\n",
    "**Pros:**\n",
    " * Fast\n",
    " * Supported by [Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html)\n",
    "\n",
    "**Cons:**\n",
    " * Like Ï‡Â², it may not generalize to the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yImXX9NFNYoN"
   },
   "source": [
    "#### **3.3.4: Mixed Methods**\n",
    "Combining methods is common. Start with expert feature selection, then add synthetic methods. Test different approaches, but be cautious of overfitting. Always evaluate using a solid validation set, not the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b3abGJZH1lcA"
   },
   "source": [
    "## **Assignment \\#4b (BONUS, not graded): Finish Expert Feature Selection & Find another Feature Selection Method to Use.**\n",
    "\n",
    "Finish the coding for expert feature selection and use another feature selection method like PCA/mutual information/wrapper methods for use in your model. Which one performs best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "IMsLIXw-0S8T"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_jiIKtcA3ayK"
   },
   "source": [
    "# **4. K-Fold Cross Validation: Systematically evaluating your model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rvdx6ecL3g55"
   },
   "source": [
    "K-fold cross-validation is a resampling procedure used to systematically evaluate machine learning models. The procedure has a parameter called k that refers to the number of groups that a given data sample is to be split into. This technique is important in machine learning because it ensures that every observation from the original dataset has the chance of appearing in the training and test set, providing a thorough assessment of how well a model performs across different subsets of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "6VEo-0v13gFi"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "## Define k\n",
    "k = 3\n",
    "\n",
    "## Initialize k-fold setup for cross-validation\n",
    "kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Running through folds\n",
    "for train_index, val_index in kf.split(train_x[columns_to_use], train_y_vector):\n",
    "    \n",
    "    # Use iloc for integer-location indexing\n",
    "      X_train, X_test = train_x[columns_to_use].iloc[train_index], train_x[columns_to_use].iloc[val_index]\n",
    "      y_train, y_test = train_y_vector.iloc[train_index], train_y_vector.iloc[val_index]\n",
    "\n",
    "      # Now we can fit the model, generate predictions, and compare the performance with validation labels y_val.\n",
    "      # Once that is done, we save the results for next fold/iteration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bdi2Bs7v3l9c"
   },
   "source": [
    "## **Assignment \\#6: Perform k-fold cross-validation**\n",
    "\n",
    "Evaluate an ML model of your choosing (Logistic Regression, etc...) under 5-fold cross-validation. Print the macro average precision, recall, and f1-scores in each fold. Print the average values across all 5 folds at the end of the loop. If you prefer, you can use sklearn's `precision_score()`, `recall_score()`, `f1_score()` instead of `classification_report()`. Please use random state 42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "uENDIGE33o_m"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #1 - Precision: 0.7843, Recall: 0.5895, F1-Score: 0.6467\n",
      "Fold #2 - Precision: 0.8064, Recall: 0.5745, F1-Score: 0.6370\n",
      "Fold #3 - Precision: 0.7898, Recall: 0.5369, F1-Score: 0.5918\n",
      "Fold #4 - Precision: 0.7973, Recall: 0.5983, F1-Score: 0.6587\n",
      "Fold #5 - Precision: 0.7986, Recall: 0.5602, F1-Score: 0.6164\n",
      "\n",
      "Average Precision: 0.7953\n",
      "Average Recall: 0.5719\n",
      "Average F1-Score: 0.6301\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "#same features\n",
    "columns_to_use = ['tve_tvi_ratio', 'tve', 'e_time', 'ep_auc', 'i_time', 'i_e_ratio']\n",
    "\n",
    "## Initialize k-fold setup for cross-validation\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "#Doing the Logistic Regression model\n",
    "model = LogisticRegression(random_state=42)\n",
    "\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "# Loop through the 5 folds\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(train_x[columns_to_use], train_y_vector), 1):  # start fold from 1\n",
    "    \n",
    "# using the .iloc just like the TA said\n",
    "    X_train, X_val = train_x[columns_to_use].iloc[train_index], train_x[columns_to_use].iloc[val_index]\n",
    "    y_train, y_val = train_y_vector.iloc[train_index], train_y_vector.iloc[val_index]\n",
    "    \n",
    "    # fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # make predictions\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # used macro average due to it giving each class the same importance regardless of its size.\n",
    "    precision = precision_score(y_val, y_pred, average='macro', zero_division=0)\n",
    "    recall = recall_score(y_val, y_pred, average='macro', zero_division=0)\n",
    "    f1 = f1_score(y_val, y_pred, average='macro', zero_division=0)\n",
    "    \n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    \n",
    "#make our print statements look like the ones in the slide\n",
    "    print(f\"Fold #{fold} - Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}\")\n",
    "\n",
    "avg_precision = np.mean(precision_scores)\n",
    "avg_recall = np.mean(recall_scores)\n",
    "avg_f1 = np.mean(f1_scores)\n",
    "\n",
    "print(f\"\\nAverage Precision: {avg_precision:.4f}\")\n",
    "print(f\"Average Recall: {avg_recall:.4f}\")\n",
    "print(f\"Average F1-Score: {avg_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3FMEfeCe3s1v"
   },
   "source": [
    "**Q: In the tutorial, you are taught to use the function StratifiedKFold. What does it mean when we stratify our k-folds?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YD-3ZmPf3u7E"
   },
   "outputs": [],
   "source": [
    "It means that the folds are created so that they maintain the number of samples of each class in the data. This make it that \n",
    "each fold has a similar distribution of classes as the original dataset. Doing the normal k-fold makes the data split randomly\n",
    "into subsets without considering the class labels, but doing the k-fold confirms that each fold contains approximately \n",
    "the same proportion of samples from each class as in the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
